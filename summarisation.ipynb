{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.agents.tools import Tool\n",
    "from langchain.llms.base import LLM\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.agents import load_tools, initialize_agent, AgentExecutor, BaseSingleActionAgent, AgentType\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PDFMinerLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "os.chdir(\"/notebooks/learn-langchain\")\n",
    "from langchain_app.models.text_generation_web_ui import (\n",
    "    build_text_generation_web_ui_client_llm,\n",
    ")\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.callbacks import AimCallbackHandler, StdOutCallbackHandler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Суммаризация текста"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Суммаризация текста без использования метода Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = build_text_generation_web_ui_client_llm(parameters={\n",
    "    \"max_new_tokens\": 300,\n",
    "    \n",
    "    })\n",
    "\n",
    "template = \"\"\"\n",
    "Write a concise summary of the following:\n",
    "\n",
    "{question}\n",
    "\n",
    "CONCISE SUMMARY:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "question = \"\"\"\n",
    "\n",
    "Updates to Fraud and Consumer Dispute Rules\n",
    "Global (excluding Brazil) | Acquirers, Issuers, Processors, Agents Visa, Interlink, Plus Networks; V PAY\n",
    "Overview: Visa has updated dispute rule language and made additional revisions to dispute rules for clarity and consistency based on client feedback. The updated rules will be effective for disputes processed on or after 14 October 2023, unless otherwise specified.\n",
    "To promote more efficient dispute resolution for clients, Visa is eliminating rule language that is outdated or no longer required, standardizing rules to make them easier to interpret and use and making modifications to increase flexibility.\n",
    "As a result, the following changes are being made to the Visa Rules sections\n",
    "below effective for disputes processed on or after 14 October 2023, unless\n",
    "otherwise specified. Refer to the advance copies of the changes in the Additional Resources section below for more information.\n",
    "• Use of Compelling Evidence / Allowable Compelling Evidence (disputes involving Europe region)\n",
    "• Pre-Arbitration Processing Requirements for Dispute Condition 10.1: EMV Liability Shift—Counterfeit Fraud, Dispute Condition 10.2: EMV Liability Shift—Non-Counterfeit Fraud, Dispute Condition 10.3: Other Fraud— Card-Present Environment and Dispute Condition 10.4: Other Fraud—Card-Absent Environment\n",
    "• Dispute Condition 10.4: Other Fraud—Card-Absent Environment\n",
    "• Dispute Reasons for Dispute Condition 12.6: Duplicate Processing / Paid By Other Means\n",
    "• Invalid Disputes for Dispute Condition 13.3: Not as Described or Defective Merchandise / Services\n",
    "In addition, Visa has updated the rules language related to dispute / pre-arbitration processing requirements and supporting documentation / certification, and has also made miscellaneous rule updates to the following dispute conditions and compliance processing requirements:\n",
    "• Issuer Responsibilities to Cardholders for Dispute Resolution\n",
    "• Allowable Compelling Evidence\n",
    "• Minimum Dispute Amounts\n",
    "      Mark Your Calendar:\n",
    "• Updated dispute rule language effective (14 October 2023)\n",
    " Article ID: AI12944\n",
    "• Invalid Disputes for Dispute Condition 10.3: Other Fraud—Card-Present Environment\n",
    "• Invalid Disputes for Dispute Condition 10.4: Other Fraud—Card-Absent Environment\n",
    "• Dispute Condition 13.7: Cancelled Merchandise / Services\n",
    "Allowable Compelling Evidence (Disputes Involving Europe Region)\n",
    "Currently an acquirer in the Europe region is allowed to present compelling evidence that is outside of the Allowable Compelling Evidence list. To alleviate confusion and streamline the process, the Europe region will align with the rest of the world. Effective for pre-arbitration attempts processed on or after 15 October 2023, only the items in Table 11.6—Allowable Compelling Evidence in the Visa Rules will qualify as compelling evidence (ID#: 0030221).\n",
    "Pre-Arbitration Processing Requirements for Dispute Conditions 10.1, 10.2, 10.3 and 10.4\n",
    "The Visa Rules allow certain delayed transactions, such as a transaction related to beverages from the mini fridge that occurred during a hotel stay or trip, or a parking violation that occurred while a cardholder was renting a car. Because these charges are billed after the cardholder’s departure or car rental return, an imprint for these charges cannot be obtained. However, an imprint obtained at any time during the stay / car rental (including at the time of check-in or vehicle check-out) can be used to demonstrate that the cardholder participated. Therefore, effective for pre-arbitration attempts processed on or after 14 October 2023, for a delayed transaction, the acquirer may supply evidence that the transaction relates to a prior stay, trip or rental period and evidence that an imprint was obtained during the same stay, trip or rental period to support their pre-arbitration attempt.\n",
    "Dispute Condition 10.4: Other Fraud—Card-Absent Environment\n",
    "Currently the Canada Domestic, U.S. Domestic and UK Domestic segments each have separate rules pertaining to the Address Verification Service (AVS). To align AVS rules and simplify the dispute process in these three countries, effective for pre-arbitration attempts processed on or after 14 October 2023, a dispute will not be allowed when the transaction received an authorization and the acquirer attempted to authenticate the cardholder through AVS and received a result code of U, unless the transaction was attempted with a Visa Commercial card or a card type where the cardholder is anonymous.\n",
    "As announced in the 16 June 2022 edition of the Visa Business News, the new remedy for Dispute Condition 10.4: Other Fraud—Card-Absent Environment requires an acquirer to provide a detailed description of the merchandise or services purchased. In an effort to provide the issuer with as much information / evidence to demonstrate cardholder participation, effective for pre-arbitration attempts processed on or after 14 October 2023, the acquirer will be required to supply a detailed description of the merchandise or services purchased for both the disputed transactions and the two previous undisputed transactions.\n",
    "\n",
    "\"\"\"\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different parameters of the model for text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the folder with PDF files\n",
    "input_directory = \"/notebooks/files/test/\"\n",
    "\n",
    "# Define the path to the folder with PDF files\n",
    "pdf_files = glob.glob(os.path.join(input_directory, \"*.pdf\"))\n",
    "\n",
    "# Create an instance of LLM for generating a summary based on a 200 token text Medium Size Summary (med_sum)\n",
    "llm_med_sum = build_text_generation_web_ui_client_llm(parameters={\n",
    "    \"max_new_tokens\": 200,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.4,\n",
    "    \"typical_p\": 1,\n",
    "    \"repetition_penalty\": 1.18,\n",
    "    \"top_k\": 40,\n",
    "    \"min_length\": 0,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "    \"num_beams\": 1,\n",
    "    \"penalty_alpha\": 0,\n",
    "    \"length_penalty\": 1,\n",
    "    \"early_stopping\": False,\n",
    "    \"seed\": -1,\n",
    "    \"add_bos_token\": True,\n",
    "    \"truncation_length\": 2048,\n",
    "    \"ban_eos_token\": False,\n",
    "    \"skip_special_tokens\": True,\n",
    "})\n",
    "\n",
    "# Create an instance of a text splitter into 2500 characters with an overlap of 0 characters (for summary generation)\n",
    "text_splitter_med_sum = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "# Create a chain for generating a summary\n",
    "chain_med_sum = load_summarize_chain(llm_med_sum, chain_type=\"map_reduce\", verbose=True)\n",
    "\n",
    "# Create an empty list to save the results\n",
    "results = []\n",
    "\n",
    "for file_path in pdf_files:\n",
    "    # Load PDF file\n",
    "    loader = PDFMinerLoader(file_path)\n",
    "    document = loader.load()\n",
    "    text = document[0].page_content\n",
    "\n",
    "    #  1. GENERATE MEDIUM SIZE SUMMARY\n",
    "\n",
    "    # Split text into chunks of 2500 characters\n",
    "    docs = text_splitter_med_sum.create_documents([text])\n",
    "\n",
    "    # Send documents for processing to generate summary\n",
    "    docs_med_sum = chain_med_sum.run(docs)\n",
    "\n",
    "    # Save results to list\n",
    "    results.append(docs_med_sum)\n",
    "\n",
    "# Print all results\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different parameters of the model for extracting JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DataFrame with required columns\n",
    "df = pd.DataFrame(columns=[\n",
    "    \"effective_date\", \n",
    "    \"mark_your_calendar_date\", \n",
    "    \"article_id\", \n",
    "    \"category\", \n",
    "    \"title\", \n",
    "    \"geo\", \n",
    "    \"audience\", \n",
    "    \"publication_date\"\n",
    "])\n",
    "\n",
    "# Define the path to the folder with PDF files\n",
    "input_directory = \"/notebooks/files/test/\"\n",
    "\n",
    "# Define the path to the folder with PDF files\n",
    "pdf_files = glob.glob(os.path.join(input_directory, \"*.pdf\"))\n",
    "\n",
    "# Get the first PDF file path from the list\n",
    "for file_path in pdf_files:\n",
    "\n",
    "    # Create an instance of LLM for generating a JSON extract\n",
    "    llm_extract_json = build_text_generation_web_ui_client_llm(\n",
    "        parameters={\n",
    "        \"max_new_tokens\": 100,\n",
    "        \"do_sample\": True,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.4,\n",
    "        \"typical_p\": 1,\n",
    "        \"repetition_penalty\": 1.2,\n",
    "        \"top_k\": 40,\n",
    "        \"min_length\": 0,\n",
    "        \"no_repeat_ngram_size\": 0,\n",
    "        \"num_beams\": 1,\n",
    "        \"penalty_alpha\": 0,\n",
    "        \"length_penalty\": 1,\n",
    "        \"early_stopping\": False,\n",
    "        \"seed\": -1,\n",
    "        \"add_bos_token\": True,\n",
    "        \"truncation_length\": 2048,\n",
    "        \"ban_eos_token\": False,\n",
    "        \"skip_special_tokens\": True,\n",
    "    }\n",
    "    )\n",
    "\n",
    "    # Create an instance of a text splitter to extract JSON with 5 fields\n",
    "    text_extract_json_5 = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=400,\n",
    "        chunk_overlap=0\n",
    "    )\n",
    "\n",
    "    # Create an instance of a text splitter to extract JSON with 3 fields\n",
    "    text_extract_json_3 = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=0\n",
    "    )\n",
    "\n",
    "    loader = PDFMinerLoader(file_path)\n",
    "    document = loader.load()\n",
    "    text = document[0].page_content\n",
    "\n",
    "    # Create a template for the prompt extract to JSON with 3 fields\n",
    "    template_json_3 = \"\"\"\n",
    "    Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "    ### Instruction: \n",
    "    Extract the following information from the text in input.\n",
    "    1. Effective date\n",
    "    2. Mark your calendar date\n",
    "    3. Article ID\n",
    "\n",
    "    Format instructions: JSON\n",
    "    If there is no information in the text: empty string\n",
    "    The output looks like this:\n",
    "    {output3}\n",
    "    \n",
    "    ### Input: \n",
    "    {question}\n",
    "\n",
    "    ### Response:\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a template for the prompt extract to JSON with 5 fields\n",
    "    template_json_5 = \"\"\"\n",
    "    Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "    ### Instruction: \n",
    "    Extract the following information from the text in input.\n",
    "    1. Category\n",
    "    2. Title\n",
    "    3. GEO\n",
    "    4. Audience\n",
    "    5. Publication date\n",
    "    \n",
    "    Format instructions: JSON\n",
    "    If there is no information in the text: empty string\n",
    "    # Input example: \n",
    "    Visa Business News\n",
    "    Visa Rules 13 April 2023 Introduction of Visa Rules Waiver Extension Assessments\n",
    "    AP, CEMEA, Europe, LAC | Acquirers, Issuers, Processors, Agents Visa, Interlink Networks; V PAY\n",
    "    Overview: Effective 14 October 2023, Visa will introduce waiver extension assessments for approved Visa Rules waiver extensions.\n",
    "    The Visa Rules are designed to minimize risks and provide a common, convenient\n",
    "    # Response example:\n",
    "    {output5}\n",
    "    \n",
    "    ### Input: \n",
    "    {question}\n",
    "\n",
    "    ### Response:\n",
    "    \"\"\"\n",
    "\n",
    "    # Create sub-templates for the chain\n",
    "    output3 = \"\"\"\n",
    "    {\"effective_date\": \"yyyy-mm-dd\", \"mark_your_calendar_date\": \"yyyy-mm-dd\", \"article_id\": \"\"}\n",
    "    \"\"\"\n",
    "    output5 = \"\"\"\n",
    "    {\"category\": \"Visa Rules\", \"title\": \"Introduction of Visa Rules Waiver Extension Assessments\", \"geo\": \"AP, CEMEA, Europe, LAC\", \"audience\": \"Acquirers, Issuers, Processors, Agents\", \"publication_date\": \"2023-04-13\"}\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a prompt\n",
    "    prompt_json_5 = PromptTemplate(template=template_json_5, input_variables=['question', 'output5'])\n",
    "    prompt_json_3 = PromptTemplate(template=template_json_3, input_variables=['question', 'output3'])\n",
    "\n",
    "    # Create a chain for generating a JSON extract\n",
    "    llm_chain_json_5 = LLMChain(llm=llm_extract_json, prompt=prompt_json_5)\n",
    "    llm_chain_json_3 = LLMChain(llm=llm_extract_json, prompt=prompt_json_3)\n",
    "\n",
    "    docs_json_5 = text_extract_json_5.create_documents([text])\n",
    "    docs_json_3 = text_extract_json_3.create_documents([text])\n",
    "\n",
    "    question = docs_json_5[0].page_content\n",
    "\n",
    "    json_5 = json.loads(llm_chain_json_5.run({'question': question, 'output5': output5}))\n",
    "\n",
    "    question = docs_json_3[0].page_content\n",
    "\n",
    "    json_3 = json.loads(llm_chain_json_3.run({'question': question, 'output3': output3}))\n",
    "\n",
    "    print(json_5, json_3)\n",
    "\n",
    "    combined_json = {**json_3, **json_5}\n",
    "\n",
    "    # Используем метод from_records для создания DataFrame из списка словарей\n",
    "    new_row = pd.DataFrame.from_records([combined_json])\n",
    "\n",
    "    # Добавляем новую строку к существующему DataFrame\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "# Print the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Суммаризация PDF файлов"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Суммаризация текста и сохранение результатов в текстовый файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем путь к папке с PDF-файлами\n",
    "input_directory = \"/notebooks/files\"\n",
    "\n",
    "# Получаем список PDF-файлов\n",
    "pdf_files = glob.glob(os.path.join(input_directory, \"*.pdf\"))\n",
    "\n",
    "# Создаем инстанс LLM для генерации summary на основе текста размером 200 токенов Medium Size Summary (med_sum)\n",
    "llm_med_sum = build_text_generation_web_ui_client_llm(parameters={\n",
    "    \"max_new_tokens\": 300,\n",
    "        \"do_sample\": True,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.1,\n",
    "        \"typical_p\": 1,\n",
    "        \"repetition_penalty\": 1.18,\n",
    "        \"top_k\": 40,\n",
    "        \"min_length\": 32,\n",
    "        \"no_repeat_ngram_size\": 0,\n",
    "        \"num_beams\": 1,\n",
    "        \"penalty_alpha\": 0,\n",
    "        \"length_penalty\": 1,\n",
    "        \"early_stopping\": False,\n",
    "        \"seed\": -1,\n",
    "        \"add_bos_token\": True,\n",
    "        \"truncation_length\": 2048,\n",
    "        \"ban_eos_token\": False,\n",
    "        \"skip_special_tokens\": True,\n",
    "})\n",
    "\n",
    "# Создаем инстанс LLM для получения Article ID\n",
    "llm_id = build_text_generation_web_ui_client_llm(parameters={\n",
    "    \"max_new_tokens\": 10,\n",
    "        \"do_sample\": True,\n",
    "        \"temperature\": 0.001,\n",
    "        \"top_p\": 0.1,\n",
    "        \"typical_p\": 1,\n",
    "        \"repetition_penalty\": 1.2,\n",
    "        \"top_k\": 1,\n",
    "        \"min_length\": 32,\n",
    "        \"no_repeat_ngram_size\": 0,\n",
    "        \"num_beams\": 1,\n",
    "        \"penalty_alpha\": 0,\n",
    "        \"length_penalty\": 1,\n",
    "        \"early_stopping\": False,\n",
    "        \"seed\": -1,\n",
    "        \"add_bos_token\": True,\n",
    "        \"truncation_length\": 2048,\n",
    "        \"ban_eos_token\": False,\n",
    "        \"skip_special_tokens\": True,\n",
    "})\n",
    "\n",
    "# Создаем инстанс LLM для получения Focus audience\n",
    "llm_focus = build_text_generation_web_ui_client_llm(parameters={\n",
    "    \"max_new_tokens\": 30,\n",
    "        \"do_sample\": True,\n",
    "        \"temperature\": 0.001,\n",
    "        \"top_p\": 0.1,\n",
    "        \"typical_p\": 1,\n",
    "        \"repetition_penalty\": 1.2,\n",
    "        \"top_k\": 1,\n",
    "        \"min_length\": 32,\n",
    "        \"no_repeat_ngram_size\": 0,\n",
    "        \"num_beams\": 1,\n",
    "        \"penalty_alpha\": 0,\n",
    "        \"length_penalty\": 1,\n",
    "        \"early_stopping\": False,\n",
    "        \"seed\": -1,\n",
    "        \"add_bos_token\": True,\n",
    "        \"truncation_length\": 2048,\n",
    "        \"ban_eos_token\": False,\n",
    "        \"skip_special_tokens\": True,\n",
    "})\n",
    "\n",
    "# Создаем инстанс разделителя текста на 2500 символов с перекрытием в 0 символов (для генерации summary)\n",
    "text_splitter_med_sum = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "# Создаем инстанс разделителя текста на 50 символов с перекрытием в 0 символов (для генерации Article ID)\n",
    "text_splitter_id = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=20,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "# Создаем инстанс разделителя текста на 300 символов с перекрытием в 0 символов (для генерации focus audience)\n",
    "text_splitter_focus = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "\n",
    "# Создаем template для и запрос для сбора значений Focus audience\n",
    "# template_focus = \"\"\"\n",
    "# Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "# ### Instruction:\n",
    "# Extract a list of ecommerce entities, which mentioned separated by commas in the provided text, after the article headline. EXAMPLES: Acquirers, Processors, Issuers, Agents. In the response provide only focus audience separated by comma and nothing more.\n",
    "\n",
    "# ### Input: {question}\n",
    "\n",
    "# ### Response:\n",
    "# \"\"\"\n",
    "\n",
    "# prompt_focus = PromptTemplate(template=template_focus, input_variables=[\"question\"])\n",
    "\n",
    "template_focus = \"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Extract from headline of an article the following information: 1. Article title 2. List of ecommerce entities, which mentioned separated by commas. Provide information in tabular form EXAMPLE: \n",
    "| **Article Headline** | **List of Ecommerce Entities** |\n",
    "| Article title        | Acquirers, Processors, Issuers, Agents |\n",
    "\n",
    "### Input: {question}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "prompt_focus = PromptTemplate(template=template_focus, input_variables=[\"question\"])\n",
    "\n",
    "# Создаем template для и запрос для сбора значений Article ID\n",
    "template_id = \"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Find an alphanumeric combination, following after exact phrase:'Article ID:'. In the response provide only alphanumeric combination and nothing more.\n",
    "\n",
    "### Input: {question}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "prompt_id = PromptTemplate(template=template_id, input_variables=[\"question\"])\n",
    "\n",
    "\n",
    "\n",
    "# Создаем цепочку для генерации summary\n",
    "chain_med_sum = load_summarize_chain(llm_med_sum, chain_type=\"map_reduce\", verbose=True)\n",
    "\n",
    "# Создаем цепочку для генерации Article ID\n",
    "chain_id = LLMChain(prompt=prompt_id, llm=llm_id)\n",
    "\n",
    "# Создаем цепочку для генерации Focus Audience\n",
    "chain_focus = LLMChain(prompt=prompt_focus, llm=llm_focus)\n",
    "\n",
    "for file_path in pdf_files:\n",
    "    # Загружаем PDF-файл\n",
    "    loader = PDFMinerLoader(file_path)\n",
    "    document = loader.load()\n",
    "    text = document[0].page_content\n",
    "\n",
    "    #1. ГЕНЕРАЦИЯ MEDIAN SIZE SUMMARY\n",
    "\n",
    "    #Разрезаем текст на куски по 2500 символов \n",
    "    docs = text_splitter_med_sum.create_documents([text])\n",
    "    # Отправляем документы в обработку для генерации summary\n",
    "    docs_med_sum = chain_med_sum.run(docs)\n",
    "\n",
    "    # Заменяем расширение файла на .txt и сохраняем результат\n",
    "    output_file_path = os.path.splitext(file_path)[0] + \".txt\"\n",
    "    with open(output_file_path, \"w\") as output_file:\n",
    "        output_file.write(docs_med_sum)\n",
    "\n",
    "    # # 2. ГЕНЕРАЦИЯ ARTICLE ID\n",
    "    # docs = text_splitter_id.create_documents([text])\n",
    "    # question = docs[-1]\n",
    "    # # Отправляем в обработку для генерации Article ID\n",
    "    # article_id = chain_id.run(question)\n",
    "\n",
    "    # # 3. ГЕНЕРАЦИЯ ЦЕЛЕВОЙ АУДИТОРИИ\n",
    "    # docs = text_splitter_focus.create_documents([text])\n",
    "    # question = docs[0]\n",
    "    # # Отправляем в обработку для генерации Article ID\n",
    "    # focus = chain_focus.run(question)\n",
    "\n",
    "    print(f\"Обработан файл: {file_path}\")\n",
    "    print(f\"Article ID: {article_id}\")\n",
    "    print(f\"Focus audience: {focus}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Берем PDF документ и делаем из него текстовый файл с помощью langchain.document_loaders.PDFMinerLoader\n",
    "file_path = '/notebooks/files/AI12944 - Updates to Fraud and Consumer Dispute Rules.pdf'\n",
    "loader = PDFMinerLoader(file_path)\n",
    "document = loader.load()\n",
    "\n",
    "text = document[0].page_content\n",
    "\n",
    "llm = build_text_generation_web_ui_client_llm(parameters={\n",
    "    \"max_new_tokens\": 200,\n",
    "        \"do_sample\": True,\n",
    "        \"temperature\": 0.001,\n",
    "        \"top_p\": 0.1,\n",
    "        \"typical_p\": 1,\n",
    "        \"repetition_penalty\": 1.2,\n",
    "        \"top_k\": 1,\n",
    "        \"min_length\": 32,\n",
    "        \"no_repeat_ngram_size\": 0,\n",
    "        \"num_beams\": 1,\n",
    "        \"penalty_alpha\": 0,\n",
    "        \"length_penalty\": 1,\n",
    "        \"early_stopping\": False,\n",
    "        \"seed\": -1,\n",
    "        \"add_bos_token\": True,\n",
    "        \"truncation_length\": 2048,\n",
    "        \"ban_eos_token\": False,\n",
    "        \"skip_special_tokens\": True,\n",
    "    })\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2500,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "docs = text_splitter.create_documents([text])\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose = True)\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1700,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "docs = text_splitter.create_documents([text])\n",
    "\n",
    "content = docs[0].page_content\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "docs = text_splitter.create_documents([text])\n",
    "\n",
    "content = docs[-1].page_content\n",
    "\n",
    "llm = build_text_generation_web_ui_client_llm(parameters={\n",
    "    \"max_new_tokens\": 10,\n",
    "        \"do_sample\": True,\n",
    "        \"temperature\": 0.001,\n",
    "        \"top_p\": 0.1,\n",
    "        \"typical_p\": 1,\n",
    "        \"repetition_penalty\": 1.2,\n",
    "        \"top_k\": 1,\n",
    "        \"min_length\": 1,\n",
    "        \"no_repeat_ngram_size\": 0,\n",
    "        \"num_beams\": 1,\n",
    "        \"penalty_alpha\": 0,\n",
    "        \"length_penalty\": 1,\n",
    "        \"early_stopping\": False,\n",
    "        \"seed\": -1,\n",
    "        \"add_bos_token\": True,\n",
    "        \"truncation_length\": 2048,\n",
    "        \"ban_eos_token\": False,\n",
    "        \"skip_special_tokens\": True,\n",
    "})\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Find an alphanumeric combination, following after exact phrase:'Article ID:'. In the response provide only alphanumeric combination and nothing more.\n",
    "\n",
    "### Input: {question}\n",
    "\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "llm_chain.run(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = build_text_generation_web_ui_client_llm(parameters={\n",
    "    \"max_new_tokens\": 100,\n",
    "        \"do_sample\": True,\n",
    "        \"temperature\": 0.001,\n",
    "        \"top_p\": 0.1,\n",
    "        \"typical_p\": 1,\n",
    "        \"repetition_penalty\": 1.2,\n",
    "        \"top_k\": 1,\n",
    "        \"min_length\": 32,\n",
    "        \"no_repeat_ngram_size\": 0,\n",
    "        \"num_beams\": 1,\n",
    "        \"penalty_alpha\": 0,\n",
    "        \"length_penalty\": 1,\n",
    "        \"early_stopping\": False,\n",
    "        \"seed\": -1,\n",
    "        \"add_bos_token\": True,\n",
    "        \"truncation_length\": 2048,\n",
    "        \"ban_eos_token\": False,\n",
    "        \"skip_special_tokens\": True,\n",
    "    })\n",
    "\n",
    "template = \"\"\"\n",
    "Write a concise summary of the following:\n",
    "\n",
    "{question}\n",
    "\n",
    "CONCISE SUMMARY:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "class Document:\n",
    "    def __init__(self, page_content, metadata):\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata\n",
    "\n",
    "\n",
    "def process_documents(docs, llm_chain):\n",
    "    results = []\n",
    "\n",
    "    for doc in docs:\n",
    "        content = doc.page_content\n",
    "        result = llm_chain.run(content)\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "results = process_documents(docs, llm_chain)\n",
    "\n",
    "# Если вы хотите совместить результаты в одну строку\n",
    "combined_results = ' '.join(results)\n",
    "\n",
    "print(combined_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = build_text_generation_web_ui_client_llm(parameters={\n",
    "    \"max_new_tokens\": 200,\n",
    "    })\n",
    "\n",
    "question = \"\"\"\n",
    "\n",
    "DISPUTE RESOLUTION:\n",
    "Visa Business News \n",
    "\n",
    "Dispute Resolution \n",
    "\n",
    "20 April 2023 \n",
    "\n",
    "This article originally appeared in the Visa Europe has introduced new allowable compelling evidence in cases where the cardholder disputes a transaction that is not eligible for dispute under the standard Visa Rules. This evidence must be provided by the issuer within 45 days of receipt of the dispute from the acquirer. If the issuer fails to provide this evidence within the required timeframe, the dispute will automatically be declined. The following are the types of compelling evidence that may be submitted Effective for pre-arbitration attempts processed on or after 15 October 2023, only the items in Table 11.6—Allowable Compelling Evidence in the Visa Rules will qualify as compelling evidence for dispute conditions 10.1, 10.2, 10.3 and 10.4. In addition, for delayed transactions, the acquirer may provide evidence that the transaction relates Effective for pre-arbitration attempts processed on or after 14 October 2023, a duplicate processing dispute will \n",
    "not be allowed when the acquirer has not provided the merchant name and address where the goods or services were \n",
    "purchased. The acquirer must also provide the date the goods or services were purchased, the amount charged, and \n",
    "the method of payment used for the original purchase.  \n",
    "\n",
    "Dispute Condition \n",
    "- Effective for disputes processed on or after 14 October 2023, an issuer will be allowed to dispute a single transaction that was processed more than once only if the transaction was processed with the same payment credential on the same transaction date and for the same transaction amount.\n",
    "\n",
    "- Effective for disputes processed on or after 14 October 2023, the dispute rights rule will be updated to clarify that the cardholder (or \n",
    "For disputes related to MCC code 4722, the issuer must wait 30 calendar days from the date the merchant cancelled the service prior to processing a dispute.\n",
    "\n",
    "Effective for disputes processed on or after 14 October 2023, the issuer will not be required to wait 30 calendar days for a dispute related to non-receipt of travel services from a provider that is insolvent or bankrupt, \n",
    "The rule update will require issuers and acquirers to conduct a thorough investigation before processing a dispute to ensure that the dispute is valid according to the Visa rules. The minimum dispute amount for fuel dispenser transactions will also be removed. The rule update will clarify the use of imprints in disputes and will remove obsolete language related to unattended transactions and Visa Easy Payment Service.  \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "summary = llm_chain.run(question)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question = \"What is the meaning of life?\"\n",
    "llm_chain.run(question)\n",
    "!wget https://raw.githubusercontent.com/hwchase17/langchainjs/main/examples/state_of_the_union.txt\n",
    "def search_context(src, phrase, buffer=100):\n",
    "    with open(src, 'r') as f:\n",
    "        txt=f.read()\n",
    "\n",
    "    words = txt.split()\n",
    "    index = words.index(phrase)\n",
    "    start_index = max(0, index - buffer)\n",
    "    end_index = min(len(words), index + buffer+1)\n",
    "    return ' '.join(words[start_index:end_index])\n",
    "\n",
    "fragment = './fragment.txt'\n",
    "with open(fragment, 'w') as fo:\n",
    "    _txt = search_context('./state_of_the_union.txt', \"Ketanji\")\n",
    "    fo.write(_txt)\n",
    "\n",
    "!cat $fragment\n",
    "from langchain.embeddings import LlamaCppEmbeddings\n",
    "\n",
    "llama_embeddings = LlamaCppEmbeddings(model_path=GPT4ALL_MODEL_PATH)\n",
    "loader = TextLoader('./fragment.txt')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textgen",
   "language": "python",
   "name": "textgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
